# Тестовое задание: Прогнозирование качества вин

## Введение

Целью данного проекта является разработка модели машинного обучения для прогнозирования качества красных вин на основе их химических свойств. Модель позволяет определить оценку качества вина по количественным показателям его химического состава.

## Используемые данные

Для обучения модели использовался набор данных "Wine Quality" из репозитория UCI Machine Learning. Набор данных содержит информацию о красных винах (winequality-red.csv) и включает 1599 образцов. 

Каждый образец описывается 11 признаками (химическими свойствами):
- fixed acidity (фиксированная кислотность)
- volatile acidity (летучая кислотность)
- citric acid (лимонная кислота)
- residual sugar (остаточный сахар)
- chlorides (хлориды)
- free sulfur dioxide (свободный диоксид серы)
- total sulfur dioxide (общий диоксид серы)
- density (плотность)
- pH (кислотность)
- sulphates (сульфаты)
- alcohol (содержание алкоголя)

Целевая переменная quality представляет собой оценку качества вина по шкале от 0 до 10, хотя в данном наборе данных фактический диапазон составляет от 3 до 8.

## Этапы работы

### Загрузка и анализ данных

После загрузки данных был проведен исследовательский анализ:
- Проверка наличия пропущенных значений (пропуски отсутствуют)
- Анализ распределения признаков: некоторые признаки имеют асимметричное распределение
- Анализ корреляций между признаками и целевой переменной

Наибольшую корреляцию с quality показали признаки:
- alcohol (положительная корреляция)
- volatile acidity (отрицательная корреляция)
- sulphates (положительная корреляция)

Распределение оценок качества в наборе данных:
- Качество 3: 10 образцов
- Качество 4: 53 образцов
- Качество 5: 681 образцов
- Качество 6: 638 образцов
- Качество 7: 199 образцов
- Качество 8: 18 образцов

Большинство вин имеет среднее качество (5-6), что создает несбалансированность в наборе данных.

### Предобработка данных

Данные были предобработаны следующим образом:
1. Стандартизация признаков с использованием StandardScaler для приведения всех признаков к одному масштабу
2. Разделение на обучающую и тестовую выборки в соотношении 80/20 (стратифицированное разделение по целевой переменной)

### Архитектура модели

Для предсказания качества вина использовалась нейронная сеть прямого распространения (FNN) с архитектурой:
- Входной слой: 11 нейронов (по числу признаков)
- Первый скрытый слой: 64 нейрона с функцией активации ReLU
- Второй скрытый слой: 32 нейрона с функцией активации ReLU
- Выходной слой: 1 нейрон (регрессия)

Обучение модели:
- Функция потерь: MSE (Mean Squared Error)
- Оптимизатор: Adam с learning rate = 0.001
- Количество эпох: 300
- Размер мини-батча: 64

### Метрики

Для оценки качества модели использовались следующие метрики:
1. MSE (Mean Squared Error) - среднеквадратичная ошибка, основная метрика для оптимизации, чувствительна к выбросам
2. MAE (Mean Absolute Error) - средняя абсолютная ошибка, менее чувствительна к выбросам и интуитивно понятна
3. R² (коэффициент детерминации) - показывает долю дисперсии целевой переменной, объясненной моделью

## Визуализации

В ходе проекта были созданы следующие визуализации (находятся в директории results):

1. learning_curves.png - график кривых обучения, показывающий динамику функции потерь на обучающей и тестовой выборках в процессе обучения

2. predictions.png - диаграмма рассеяния, сравнивающая истинные значения качества вина с предсказанными моделью

3. error_histogram.png - гистограмма ошибок предсказания, показывающая распределение ошибок модели

4. residuals.png - график остатков (разница между истинными и предсказанными значениями) относительно предсказанных значений

## Результаты

Финальные метрики модели на тестовой выборке:
- MSE: 0.4785
- MAE: 0.5446
- R²: 0.3231

## Выводы

Модель показала умеренную эффективность в предсказании качества вин на основе их химических свойств. Коэффициент детерминации (R²) около 0.32 говорит о том, что модель объясняет примерно 32% дисперсии в целевой переменной.

Анализ ошибок предсказания показал, что модель:
- Имеет тенденцию завышать оценку для низкокачественных вин (качество 3-4)
- Занижает оценку для высококачественных вин (качество 7-8)
- Наиболее точно предсказывает вина со средним качеством (5-6), что может быть связано с преобладанием таких образцов в обучающей выборке

Направления для улучшения модели:
1. Работа с несбалансированностью данных (применение техник сэмплирования или весовых функций потерь)
2. Гиперпараметрическая оптимизация (подбор оптимальных параметров модели через GridSearch или Bayesian Optimization)
3. Испробовать различные архитектуры нейронных сетей (большее количество слоев, другие функции активации)
4. Применение регуляризации (L1, L2, Dropout) для предотвращения переобучения
5. Использование ансамблевых методов (комбинирование нейронной сети с градиентным бустингом или случайным лесом)
6. Проведение feature engineering (создание новых признаков на основе существующих)
7. Применение кросс-валидации для более надежной оценки производительности модели

В целом задача прогнозирования качества вина оказалась сложной, вероятно из-за субъективности оценок качества и ограниченного набора доступных признаков. Для более точных предсказаний может потребоваться дополнительная информация о винах, которая не была представлена в исходном наборе данных.

## Направления для улучшения

Для дальнейшего совершенствования модели можно предложить следующие шаги:

1. **Расширение набора данных**: Включение дополнительных признаков или увеличение объема выборки.

2. **Гиперпараметрическая оптимизация**: Использование методов автоматического подбора гиперпараметров (например, GridSearch, Bayesian Optimization).

3. **Ансамблевые методы**: Комбинирование нейронной сети с другими моделями машинного обучения для улучшения точности.

4. **Углубление архитектуры**: Тестирование более сложных архитектур нейронных сетей с дополнительными слоями или другими типами активации.

5. **Кросс-валидация**: Применение k-fold кросс-валидации для более надежной оценки производительности модели.

## Библиотеки и инструменты

Проект реализован с использованием следующих библиотек:
- pandas
- numpy
- scikit-learn
- matplotlib
- seaborn
- PyTorch 